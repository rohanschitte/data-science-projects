{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "name": "Task8.3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76op8P9gmG9u",
        "outputId": "da25c3da-b3fa-455c-ae25-e7c1cabfbfd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyfaoUe4mAUM",
        "outputId": "5a48125d-f75c-405a-90d8-643cf82e93b6"
      },
      "source": [
        "## LABEL DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "labels = pd.read_csv('/content/drive/MyDrive/introToFADS/week8/studentLife_no-audio__no-wifi/studentLife/survey/PerceivedStressScale.csv')\n",
        "\n",
        "# there are 39 post responses and 46 pre responses\n",
        "labelsproc = np.empty(39, dtype=np.int64)\n",
        "\n",
        "\n",
        "# takes THE PerceivedStressedScale.csv and a zeroed array, populates zeroed array\n",
        "# with stress scores\n",
        "def surveyIntoStressScore(X, y):\n",
        "    \n",
        "    arr = np.ones((39,9))\n",
        "    colLabels = X.columns.values.tolist()\n",
        "    \n",
        "    # converts every survey answer into scores\n",
        "    # populates arr with scores\n",
        "    for i in range(0,39):\n",
        "        for j in range(2,11):\n",
        "            arr[i,j-2] = textToScore(X[colLabels[j]][46+i])\n",
        "        \n",
        "    sumArr = np.sum(arr, axis=1)\n",
        "        \n",
        "    return sumArr;  \n",
        "\n",
        "def textToScore(str):\n",
        "    if str == 'Never':\n",
        "        return 0;\n",
        "    elif str == 'Almost never':\n",
        "        return 1;\n",
        "    elif str == 'Sometime':\n",
        "        return 2;\n",
        "    elif str == 'Fairly often':\n",
        "        return 3;\n",
        "    elif str == 'Very often':\n",
        "        return 4;\n",
        "    \n",
        "\n",
        "labelsproc.size\n",
        "labelVector = surveyIntoStressScore(labels,labelsproc)\n",
        "# print(labelVector)\n",
        "# prints out label vector containing stress scores of \n",
        "# participants who replied to the post Stress\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## GPS DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# 1->'01' 25->'25'\n",
        "def doubleDigitizer(x):\n",
        "    if x < 10:\n",
        "        return '0' + str(x);\n",
        "    else:\n",
        "        return str(x);\n",
        "\n",
        "# to identify missing\n",
        "missing_vectors = np.array([])\n",
        "\n",
        "    \n",
        "# here are 60 users from gps_u00 to gps_u59\n",
        "# populate df_collection with every gps data for every user\n",
        "df_collection = {}\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        df_collection[ddi] = pd.read_csv('/content/drive/MyDrive/introToFADS/week8/studentLife_no-audio__no-wifi/studentLife/sensing/gps/gps_u' + ddi + '.csv')\n",
        "    except IOError:\n",
        "        print \"no user # \" + ddi + \" for GPS\"\n",
        "        missing_vectors = np.append(missing_vectors,ddi)\n",
        "        pass\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "def distBetweenTwoCoords(lat1,lon1,lat2,lon2):\n",
        "    \n",
        "    R = 6371 # Radius of Earth in km\n",
        "\n",
        "    dLat = math.radians(float(lat2) - float(lat1))\n",
        "    dLon = math.radians(float(lon2) - float(lon1))\n",
        "    lat1 = math.radians(float(lat1))\n",
        "    lat2 = math.radians(float(lat2))\n",
        "    \n",
        "    a = math.sin(dLat/2) * math.sin(dLat/2) + \\\n",
        "        math.cos(lat1) * math.cos(lat2) * math.sin(dLon/2) * math.sin(dLon/2)\n",
        "\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
        "\n",
        "    d = R * c\n",
        "\n",
        "    return d;\n",
        "\n",
        "#assumes input is DataFrame, with labeled latitude and longitude columns\n",
        "\n",
        "def totalDistCovered(X):\n",
        "    \n",
        "    sum = 0\n",
        "    \n",
        "    lats = X['latitude']\n",
        "    lons = X['longitude']\n",
        "    \n",
        "    for i in range(0,(lats.size-1)):\n",
        "        sum += distBetweenTwoCoords(lats.get_values()[i],lons.get_values()[i],lats.get_values()[i+1],lons.get_values()[i+1])\n",
        "                \n",
        "    return sum;\n",
        "df_collection2={}\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        df_collection2[ddi] = pd.read_csv('/content/drive/MyDrive/introToFADS/week8/studentLife_no-audio__no-wifi/studentLife/sensing/activity/activity_u' + ddi + '.csv')\n",
        "\n",
        "    except IOError:\n",
        "      pass\n",
        "      print \"no user # \" + ddi + \" for activity\"\n",
        "\n",
        "def activityE(X):\n",
        "  activity_value = 0\n",
        "  activity_value = sum(X[' activity inference'].get_values())\n",
        "  return activity_value\n",
        "\n",
        "activityFeatureVector = np.zeros((60,1))\n",
        "for i in range(0,60):\n",
        "  ddi = doubleDigitizer(i)\n",
        "  try:\n",
        "    activityFeatureVector[i,0]=  activityE(df_collection2[ddi])\n",
        "  except KeyError:\n",
        "    activityFeatureVector[i,0] = np.NaN\n",
        "\n",
        "gpsFeatureVector = np.zeros((60,1))\n",
        "\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        gpsFeatureVector[i,0] = totalDistCovered(df_collection[ddi])\n",
        "    except KeyError:\n",
        "        gpsFeatureVector[i,0] = np.NaN\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "## smsDATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# 1->'01' 25->'25'\n",
        "def doubleDigitizer(x):\n",
        "    if x < 10:\n",
        "        return '0' + str(x);\n",
        "    else:\n",
        "        return str(x);\n",
        "\n",
        "# here are 60 users from gps_u00 to gps_u59\n",
        "# populate df_collection with every gps data for every user\n",
        "df_collection = {}\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        df_collection[ddi] = pd.read_csv('/content/drive/MyDrive/introToFADS/week8/studentLife_no-audio__no-wifi/studentLife/sms/sms_u' + ddi + '.csv')\n",
        "    except IOError:\n",
        "        pass\n",
        "        print \"no user # \" + ddi + \" for SMS\"\n",
        "        \n",
        "from datetime import datetime\n",
        "\n",
        "def timeStampToDatetime(ts):\n",
        "    return datetime.utcfromtimestamp(float(ts))\n",
        "\n",
        "# outputs datetime.datetime(2013, 3, 24, 4, 31, 22)\n",
        "# that's for year, month, day, hour, minute, second\n",
        "\n",
        "# int1 is first time, int2 is last time, returns days elapsed in between\n",
        "def daysInBetween(int1, int2):\n",
        "    secs = int2 - int1\n",
        "    return secs/86400;\n",
        "\n",
        "\n",
        "def dailySmsFreq(X):\n",
        "    ts = X['timestamp']\n",
        "    return (ts.size)/daysInBetween(ts[0], ts[ts.size-1]);\n",
        "\n",
        "\n",
        "smsFeatureVector = np.zeros((60,1))\n",
        "\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        smsFeatureVector[i,0] = dailySmsFreq(df_collection[ddi])\n",
        "    except KeyError:\n",
        "        smsFeatureVector[i,0] = np.NaN\n",
        "    \n",
        "## CALLLOG DATA\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def doubleDigitizer(x):\n",
        "    if x < 10:\n",
        "        return '0' + str(x);\n",
        "    else:\n",
        "        return str(x);\n",
        "\n",
        "# here are 60 users from gps_u00 to gps_u59\n",
        "# populate df_collection with every gps data for every user\n",
        "df_collection = {}\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        df_collection[ddi] = pd.read_csv('/content/drive/MyDrive/introToFADS/week8/studentLife_no-audio__no-wifi/studentLife/call_log/call_log_u' + ddi + '.csv')\n",
        "    except IOError:\n",
        "        pass\n",
        "        print \"no user # \" + ddi + \" for CALL\"\n",
        "        \n",
        "from datetime import datetime\n",
        "\n",
        "def timeStampToDatetime(ts):\n",
        "    return datetime.utcfromtimestamp(float(ts))\n",
        "\n",
        "# outputs datetime.datetime(2013, 3, 24, 4, 31, 22)\n",
        "# that's for year, month, day, hour, minute, second\n",
        "\n",
        "# int1 is first time, int2 is last time, returns days elapsed in between\n",
        "def daysInBetween(int1, int2):\n",
        "    secs = int2 - int1\n",
        "    return secs/86400;\n",
        "\n",
        "def dailyCallFreq(X):\n",
        "    ts = X['timestamp']\n",
        "    return (ts.size)/daysInBetween(ts[0], ts[ts.size-1]);\n",
        "\n",
        "# dailyCallFreq(df_collection['00'])\n",
        "\n",
        "callFeatureVector = np.zeros((60,1))\n",
        "\n",
        "for i in range(0,60):\n",
        "    ddi = doubleDigitizer(i)\n",
        "    try:\n",
        "        callFeatureVector[i,0] = dailyCallFreq(df_collection[ddi])\n",
        "    except KeyError:\n",
        "        callFeatureVector[i,0] = np.NaN\n",
        "    \n",
        "\n",
        "a1 = gpsFeatureVector\n",
        "a2 = activityFeatureVector\n",
        "a3 = smsFeatureVector\n",
        "a4 = callFeatureVector\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no user # 06 for GPS\n",
            "no user # 11 for GPS\n",
            "no user # 21 for GPS\n",
            "no user # 26 for GPS\n",
            "no user # 28 for GPS\n",
            "no user # 29 for GPS\n",
            "no user # 37 for GPS\n",
            "no user # 38 for GPS\n",
            "no user # 40 for GPS\n",
            "no user # 48 for GPS\n",
            "no user # 55 for GPS\n",
            "no user # 06 for activity\n",
            "no user # 11 for activity\n",
            "no user # 21 for activity\n",
            "no user # 26 for activity\n",
            "no user # 28 for activity\n",
            "no user # 29 for activity\n",
            "no user # 37 for activity\n",
            "no user # 38 for activity\n",
            "no user # 40 for activity\n",
            "no user # 48 for activity\n",
            "no user # 55 for activity\n",
            "no user # 06 for SMS\n",
            "no user # 11 for SMS\n",
            "no user # 21 for SMS\n",
            "no user # 26 for SMS\n",
            "no user # 28 for SMS\n",
            "no user # 29 for SMS\n",
            "no user # 37 for SMS\n",
            "no user # 38 for SMS\n",
            "no user # 40 for SMS\n",
            "no user # 48 for SMS\n",
            "no user # 55 for SMS\n",
            "no user # 06 for CALL\n",
            "no user # 11 for CALL\n",
            "no user # 21 for CALL\n",
            "no user # 26 for CALL\n",
            "no user # 28 for CALL\n",
            "no user # 29 for CALL\n",
            "no user # 37 for CALL\n",
            "no user # 38 for CALL\n",
            "no user # 40 for CALL\n",
            "no user # 48 for CALL\n",
            "no user # 55 for CALL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjlVkwmmAUS",
        "outputId": "9972f382-ca11-4bb9-d01a-c19bcad4400a"
      },
      "source": [
        "featureMatrix = np.hstack((a1,a2,a3,a4))\n",
        "\n",
        "## KNN\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import operator\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "\n",
        "def ffill_cols(a, startfillval=0):\n",
        "    mask = np.isnan(a)\n",
        "    tmp = a[0].copy()\n",
        "    a[0][mask[0]] = startfillval\n",
        "    mask[0] = False\n",
        "    idx = np.where(~mask,np.arange(mask.shape[0])[:,None],0)\n",
        "    out = np.take_along_axis(a,np.maximum.accumulate(idx,axis=0),axis=0)\n",
        "    a[0] = tmp\n",
        "    return out\n",
        "\n",
        "# removing NULLs\n",
        "missing_vectors = np.array([6,11,21,26,28,29,37,38,40,48,55])\n",
        "\n",
        "for i in range(0,missing_vectors.size):\n",
        "    \n",
        "    featureMatrix = np.delete(featureMatrix, int(missing_vectors[i])-i, 0)\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "cutoff = 20\n",
        "print(featureMatrix.shape)\n",
        "# shuffles matrix\n",
        "np.random.shuffle(featureMatrix)\n",
        "\n",
        "train = featureMatrix[0:cutoff]\n",
        "\n",
        "test = featureMatrix[cutoff:39]\n",
        "\n",
        "trainl = labelVector[0:cutoff]\n",
        "testl = labelVector[cutoff:39]\n",
        "knn.fit(train, trainl)\n",
        "ypred = knn.predict(test)\n",
        "\n",
        "# print(result)\n",
        "\n",
        "print(accuracy_score(testl, ypred))\n",
        "\n",
        "print(1-(float(abs(sum(map(operator.sub,testl,ypred))))/float(sum(testl))))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 4)\n",
            "0.2631578947368421\n",
            "0.974285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6R26qlmAUT",
        "outputId": "72170e9c-53c6-42da-83f2-9c84462e311b"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "cutoff = 20\n",
        "\n",
        "train = featureMatrix[0:cutoff]\n",
        "test = featureMatrix[cutoff:39]\n",
        "\n",
        "trainl = labelVector[0:cutoff]\n",
        "testl = labelVector[cutoff:39]\n",
        "\n",
        "\n",
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(train, trainl)\n",
        "\n",
        "# predict the response values for the observations in X\n",
        "y_pred = logreg.predict(test)\n",
        "print(metrics.accuracy_score(testl, y_pred))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}